{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Buddhilive_Response.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Pu7eIceChfMy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run the Trained Model\n",
        "\n",
        "Here we are going to run the trained model."
      ]
    },
    {
      "metadata": {
        "id": "Dym91t6gjrxe",
        "colab_type": "code",
        "outputId": "1846e61b-b8b2-49ae-958a-9807aff420bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# things we need for NLP\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tkxd4dztQCW6",
        "colab_type": "code",
        "outputId": "10084941-427a-4750-e685-54b1961316fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Download Datasets\n",
        "!git clone https://github.com/Buddhilive/Buddhilive.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Buddhilive' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sdYw4EZ0jrxu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import our chat-bot intents file\n",
        "import json\n",
        "with open('Buddhilive/Datasets/train_intent.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ggk43Y_0jrx1",
        "colab_type": "code",
        "outputId": "99ba6e04-5361-4087-93b9-adf98dd0c3c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?']\n",
        "# loop through each sentence in our intents patterns\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        # tokenize each word in the sentence\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        # add to our words list\n",
        "        words.extend(w)\n",
        "        # add to documents in our corpus\n",
        "        documents.append((w, intent['tag']))\n",
        "        # add to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n",
        "\n",
        "# stem and lower each word and remove duplicates\n",
        "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "# remove duplicates\n",
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "print (len(documents), \"documents\")\n",
        "print (len(classes), \"classes\", classes)\n",
        "print (len(words), \"unique stemmed words\", words)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27 documents\n",
            "11 classes ['ability', 'aboutbot', 'goodafternoon!', 'goodbye', 'goodevening', 'goodmorning', 'goodnight', 'greeting', 'noanswer', 'stupidblame', 'thanks']\n",
            "43 unique stemmed words ['!', \"'s\", '.', 'a', 'abl', 'afternoon', 'answ', 'anyon', 'ar', 'ask', 'bye', 'can', 'chatbot', 'day', 'do', 'dumb', 'ev', 'good', 'goodby', 'hello', 'help', 'hi', 'how', 'i', 'is', 'lat', 'me', 'morn', 'my', 'nam', 'night', 'not', 'quest', 'see', 'stupid', 'tel', 'thank', 'that', 'ther', 'what', 'who', 'yo', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zEEcSnMFjrx-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = load_model('Buddhilive_Model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J8MoIro9jryD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_up_sentence(sentence):\n",
        "    # tokenize the pattern\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # stem each word\n",
        "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "\n",
        "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
        "def bow(sentence, words, show_details=False):\n",
        "    # tokenize the pattern\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # bag of words\n",
        "    bag = [0]*len(words)  \n",
        "    for s in sentence_words:\n",
        "        for i,w in enumerate(words):\n",
        "            if w == s: \n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % w)\n",
        "\n",
        "    return(np.array(bag))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LHbamoSvjryJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a data structure to hold user context\n",
        "context = {}\n",
        "\n",
        "ERROR_THRESHOLD = 0.65\n",
        "def classify(sentence):\n",
        "    # generate probabilities from the model\n",
        "    p = bow(sentence, words)\n",
        "    \n",
        "    d = len(p)\n",
        "    f = len(documents)-2\n",
        "    a = np.zeros([f, d])\n",
        "    tot = np.vstack((p,a))\n",
        "    \n",
        "    results = model.predict(tot)[0]\n",
        "    \n",
        "    # filter out predictions below a threshold\n",
        "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
        "    # sort by strength of probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append((classes[r[0]], r[1]))\n",
        "    # return tuple of intent and probability\n",
        "    return return_list\n",
        "\n",
        "def response(sentence, userID, show_details=False):\n",
        "    results = classify(sentence)\n",
        "    print('Result:',results)\n",
        "    # if we have a classification then find the matching intent tag\n",
        "    if results:\n",
        "        # loop as long as there are matches to process\n",
        "        while results:\n",
        "            for i in intents['intents']:\n",
        "                # find a tag matching the first result\n",
        "                if i['tag'] == results[0][0]:\n",
        "                    # set context for this intent if necessary\n",
        "                    #print(i)\n",
        "                    if 'context_set' in i:\n",
        "                        if show_details: print ('context:', i['context_set'])\n",
        "                        context[userID] = i['context_set']\n",
        "\n",
        "                    # check if this intent is contextual and applies to this user's conversation\n",
        "                    if not 'context_filter' in i or \\\n",
        "                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n",
        "                        if show_details: print ('tag:', i['tag'])\n",
        "                        # a random response from the intent\n",
        "                        return (random.choice(i['responses']))\n",
        "            results.pop(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8KfuBJRHibdu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Check Responses\n",
        "\n",
        "Now input some queries to check whether the chatbot responds correctly."
      ]
    },
    {
      "metadata": {
        "id": "NycMprOCjryO",
        "colab_type": "code",
        "outputId": "33fdf400-388f-4fa2-d553-02e8fa372390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "response('Hello', '123', show_details=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result: [('greeting', 0.999729)]\n",
            "context: \n",
            "tag: greeting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi there, how can I help?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "YnsYBodVjryc",
        "colab_type": "code",
        "outputId": "528f3a0c-a5f9-45b1-96cc-6f90fbf20f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "response('What is your name?', '123', show_details=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result: [('aboutbot', 0.99996734)]\n",
            "tag: aboutbot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm Buddhi. A Chatbot made with Tensorflow.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "n2qWlZ9yjryj",
        "colab_type": "code",
        "outputId": "13533f41-e946-4d0d-ce48-1dcca45455da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "response('What can you do?', '123', show_details=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result: [('ability', 0.9999846)]\n",
            "tag: ability\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm designed to chat with humans like you. But I'm not intelligent like you.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "Ls-SKmGXjryx",
        "colab_type": "code",
        "outputId": "f4d096b1-1321-440d-d733-7276af32a15a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "response('Goodbye', '123', show_details=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result: [('goodbye', 0.9995646)]\n",
            "tag: goodbye\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'See you later!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}